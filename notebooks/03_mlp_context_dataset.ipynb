{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0c49651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10f2ca790>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3155aaa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repo root: /Users/home/Developer/github/makemore-notes\n",
      "num words: 32033\n",
      "first 5 words: ['emma', 'olivia', 'ava', 'isabella', 'sophia']\n"
     ]
    }
   ],
   "source": [
    "REPO_ROOT = Path.cwd()\n",
    "if (REPO_ROOT / \"data\").exists() is False and (REPO_ROOT.parent / \"data\").exists():\n",
    "    REPO_ROOT = REPO_ROOT.parent\n",
    "\n",
    "data_path = REPO_ROOT / \"data\" / \"names.txt\"\n",
    "words = data_path.read_text(encoding=\"utf-8\").splitlines()\n",
    "\n",
    "print(\"repo root:\", REPO_ROOT)\n",
    "print(\"num words:\", len(words))\n",
    "print(\"first 5 words:\", words[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0173336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 27\n",
      "itos sample: [(1, 'a'), (2, 'b'), (3, 'c'), (4, 'd'), (5, 'e'), (6, 'f'), (7, 'g'), (8, 'h'), (9, 'i'), (10, 'j')]\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(set(\"\".join(words)))\n",
    "stoi = {s: i + 1 for i, s in enumerate(chars)}\n",
    "stoi[\".\"] = 0\n",
    "itos = {i: s for s, i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "\n",
    "print(\"vocab_size:\", vocab_size)\n",
    "print(\"itos sample:\", list(itos.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bbe9f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: torch.Size([228146, 3])\n",
      "Y shape: torch.Size([228146])\n"
     ]
    }
   ],
   "source": [
    "block_size = 3  # number of characters used as context\n",
    "\n",
    "def build_dataset(words, block_size):\n",
    "    X, Y = [], []\n",
    "    for w in words:\n",
    "        context = [0] * block_size\n",
    "        for ch in w + \".\":\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix]\n",
    "    return torch.tensor(X), torch.tensor(Y)\n",
    "\n",
    "X, Y = build_dataset(words, block_size)\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"Y shape:\", Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b6d8449",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X.shape[0] == Y.shape[0]\n",
    "assert X.shape[1] == block_size\n",
    "assert X.dtype == torch.int64\n",
    "assert Y.dtype == torch.int64\n",
    "assert Y.min() >= 0 and Y.max() < vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2dd2f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 | X = '...' -> Y = 'e'\n",
      "    1 | X = '..e' -> Y = 'm'\n",
      "    2 | X = '.em' -> Y = 'm'\n",
      "    3 | X = 'emm' -> Y = 'a'\n",
      "    4 | X = 'mma' -> Y = '.'\n",
      "   20 | X = 'sab' -> Y = 'e'\n",
      "  100 | X = 'lla' -> Y = '.'\n"
     ]
    }
   ],
   "source": [
    "def decode_context(ctx):\n",
    "    return \"\".join(itos[int(i)] for i in ctx)\n",
    "\n",
    "for i in [0, 1, 2, 3, 4, 20, 100]:\n",
    "    print(\n",
    "        f\"{i:>5} | X = {decode_context(X[i])!r} -> Y = {itos[int(Y[i])]!r}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51a97c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "\n",
    "X = X.to(device)\n",
    "Y = Y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1706bc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator(device=device).manual_seed(1337)\n",
    "\n",
    "n_embed = 10     # embedding dimension\n",
    "n_hidden = 200   # hidden layer width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d375bd68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11897"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embedding table: (vocab_size, n_embed)\n",
    "C = torch.randn((vocab_size, n_embed), generator=g, device=device)\n",
    "\n",
    "# First layer: takes block_size*n_embed -> n_hidden\n",
    "W1 = torch.randn((block_size * n_embed, n_hidden), generator=g, device=device) * (5/3) / (block_size * n_embed) ** 0.5\n",
    "b1 = torch.randn((n_hidden,), generator=g, device=device) * 0.01\n",
    "\n",
    "# Output layer: n_hidden -> vocab_size\n",
    "W2 = torch.randn((n_hidden, vocab_size), generator=g, device=device) * 0.01\n",
    "b2 = torch.zeros((vocab_size,), device=device)\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2]\n",
    "for p in parameters:\n",
    "    p.requires_grad_(True)\n",
    "\n",
    "sum(p.nelement() for p in parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdb73300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xb: torch.Size([32, 3])\n",
      "emb: torch.Size([32, 3, 10])\n",
      "emb_cat: torch.Size([32, 30])\n",
      "h: torch.Size([32, 200])\n",
      "logits: torch.Size([32, 27])\n"
     ]
    }
   ],
   "source": [
    "# minibatch for sanity (faster than full dataset)\n",
    "batch_size = 32\n",
    "ix = torch.randint(0, X.shape[0], (batch_size,), generator=g, device=device)\n",
    "\n",
    "Xb, Yb = X[ix], Y[ix]  # (B, block_size), (B,)\n",
    "\n",
    "# 1) embedding lookup: (B, block_size, n_embed)\n",
    "emb = C[Xb]\n",
    "\n",
    "# 2) concatenate embeddings: (B, block_size*n_embed)\n",
    "emb_cat = emb.view(emb.shape[0], -1)\n",
    "\n",
    "# 3) hidden layer\n",
    "h_pre = emb_cat @ W1 + b1          # (B, n_hidden)\n",
    "h = torch.tanh(h_pre)              # nonlinearity\n",
    "\n",
    "# 4) logits\n",
    "logits = h @ W2 + b2               # (B, vocab_size)\n",
    "\n",
    "print(\"Xb:\", Xb.shape)\n",
    "print(\"emb:\", emb.shape)\n",
    "print(\"emb_cat:\", emb_cat.shape)\n",
    "print(\"h:\", h.shape)\n",
    "print(\"logits:\", logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d0d769d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3152, device='mps:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "loss = F.cross_entropy(logits, Yb)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdaf316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert logits.shape == (batch_size, vocab_size)\n",
    "assert Yb.shape == (batch_size,)\n",
    "assert torch.isfinite(loss).item() is True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1aef7ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (makemore-notes)",
   "language": "python",
   "name": "makemore-notes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
